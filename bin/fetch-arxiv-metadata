#!/usr/bin/env python3
"""
Process publication files to add enhanced metadata.
Fetches abstracts from arXiv and helps generate summaries.
"""

import os
import re
import sys
import urllib.request
import xml.etree.ElementTree as ET

ARXIV_API = "https://export.arxiv.org/api/query?id_list="

def extract_arxiv_id(url):
    """Extract arXiv ID from URL."""
    if not url:
        return None
    match = re.search(r'arxiv\.org/(?:abs|pdf)/(\d+\.\d+)', url)
    if match:
        return match.group(1)
    return None

def fetch_arxiv_metadata(arxiv_id):
    """Fetch metadata from arXiv API."""
    url = f"{ARXIV_API}{arxiv_id}"
    try:
        with urllib.request.urlopen(url, timeout=10) as response:
            xml_data = response.read().decode('utf-8')
        
        # Parse XML
        root = ET.fromstring(xml_data)
        ns = {'atom': 'http://www.w3.org/2005/Atom'}
        
        entry = root.find('atom:entry', ns)
        if entry is None:
            return None
        
        title = entry.find('atom:title', ns)
        summary = entry.find('atom:summary', ns)
        
        return {
            'title': title.text.strip() if title is not None else None,
            'abstract': summary.text.strip() if summary is not None else None
        }
    except Exception as e:
        print(f"Error fetching {arxiv_id}: {e}")
        return None

def main():
    if len(sys.argv) < 2:
        print("Usage: fetch-arxiv-metadata <arxiv_id_or_url>")
        sys.exit(1)
    
    arg = sys.argv[1]
    arxiv_id = extract_arxiv_id(arg) or arg
    
    print(f"Fetching metadata for arXiv:{arxiv_id}...")
    metadata = fetch_arxiv_metadata(arxiv_id)
    
    if metadata:
        print(f"\nTitle: {metadata['title']}")
        print(f"\nAbstract:\n{metadata['abstract']}")
    else:
        print("Failed to fetch metadata")

if __name__ == "__main__":
    main()
